--- original/kernel/futex.c	2021-05-04 09:30:06.298604538 -0400
+++ new	2021-05-04 09:23:18.848080087 -0400
@@ -1395,7 +1395,7 @@
 	 * its pi_state.
 	 */
 	top_waiter = futex_top_waiter(hb, key);
-	if (top_waiter)
+	if (top_waiter) // TODO Maybe here?
 		return attach_to_pi_state(uaddr, uval, top_waiter->pi_state, ps);
 
 	/*
@@ -2760,6 +2760,158 @@
 				restart->futex.val, tp, restart->futex.bitset);
 }
 
+/* TODO Besides implementing this function we need to make sure that when the 
+   user-space thread fails on 0 -> TID this will be triggered instead of 
+   FUTEX_LOCK_PI, perhaps if some extra variable is set. Same for the unlock and the rest
+   of new futex ops.
+*/
+static int futex_lock_fair_pi(u32 __user *uaddr, unsigned int flags,
+			 ktime_t *time, int trylock)
+{
+	struct hrtimer_sleeper timeout, *to;
+	struct task_struct *exiting = NULL;
+	struct rt_mutex_waiter rt_waiter;
+	struct futex_hash_bucket *hb;
+	struct futex_q q = futex_q_init;
+	int res, ret;
+
+	if (!IS_ENABLED(CONFIG_FUTEX_PI)) {
+		printk("[!!] We need compilation with CONFIG_FUTEX_PI\n");
+		return -ENOSYS;
+	}
+
+	/* Init PI state of current task */
+	if (refill_pi_state_cache())
+		return -ENOMEM;
+
+	to = futex_setup_timer(time, &timeout, FLAGS_CLOCKRT, 0);
+
+retry_fair:
+
+	/* Get keys for the futex */
+	ret = get_futex_key(uaddr, flags & FLAGS_SHARED, &q.key, FUTEX_WRITE);
+
+	if (unlikely(ret != 0))
+		goto out_fair;
+
+retry_private_fair:
+
+	hb = queue_lock(&q);
+
+	ret = futex_lock_pi_atomic(uaddr, hb, &q.key, &q.pi_state, current,
+				   &exiting, 0);
+	if (unlikely(ret)) {
+		/*
+		 * Atomic work succeeded and we got the lock,
+		 * or failed. Either way, we do _not_ block.
+		 */
+		switch (ret) {
+		case 1:
+			/* We got the lock. */
+			ret = 0;
+			goto out_unlock_put_key_fair;
+		case -EFAULT:
+			goto uaddr_faulted_fair;
+		case -EBUSY:
+		case -EAGAIN:
+			/*
+			 * Two reasons for this:
+			 * - EBUSY: Task exiting, wait for the exit to complete.
+			 * - EAGAIN: The user space value changed.
+			 */
+			queue_unlock(hb);
+			wait_for_owner_exiting(ret, exiting);
+			cond_resched();
+			goto retry_fair;
+		default:
+			goto out_unlock_put_key_fair;
+		}
+	}
+
+	WARN_ON(!q.pi_state);
+
+	/*
+	 * Only actually queue now that the atomic ops are done:
+	 */
+	__queue_me(&q, hb);
+
+	if (trylock) {
+		ret = rt_mutex_futex_trylock(&q.pi_state->pi_mutex);
+		/* Fixup the trylock return value: */
+		ret = ret ? 0 : -EWOULDBLOCK;
+		goto no_block_fair;
+	}
+
+	rt_mutex_init_waiter(&rt_waiter);
+
+	/* See explanation on futex_lock_pi() */
+	raw_spin_lock_irq(&q.pi_state->pi_mutex.wait_lock);
+	spin_unlock(q.lock_ptr);
+	
+	/* See explanation on futex_lock_pi() */
+	ret = __rt_mutex_start_proxy_lock(&q.pi_state->pi_mutex, &rt_waiter, current);
+	raw_spin_unlock_irq(&q.pi_state->pi_mutex.wait_lock);
+
+	if (ret) {
+		if (ret == 1)
+			ret = 0;
+		goto cleanup_fair;
+	}
+
+	if (unlikely(to))
+		hrtimer_sleeper_start_expires(to, HRTIMER_MODE_ABS);
+
+	ret = rt_mutex_wait_proxy_lock(&q.pi_state->pi_mutex, to, &rt_waiter);
+
+cleanup_fair:
+
+	spin_lock(q.lock_ptr);
+	
+	/* See explanation on futex_lock_pi() */
+	if (ret && !rt_mutex_cleanup_proxy_lock(&q.pi_state->pi_mutex, &rt_waiter))
+		ret = 0;
+
+no_block_fair:
+
+	/*
+	 * Fixup the pi_state owner and possibly acquire the lock if we
+	 * haven't already.
+	 */
+	res = fixup_owner(uaddr, &q, !ret);
+
+	/*
+	 * If fixup_owner() returned an error, proprogate that.  If it acquired
+	 * the lock, clear our -ETIMEDOUT or -EINTR.
+	 */
+	if (res)
+		ret = (res < 0) ? res : 0;
+
+	/* Unqueue and drop the lock */
+	unqueue_me_pi(&q);
+	goto out_fair;
+
+out_unlock_put_key_fair:
+	queue_unlock(hb);
+
+out_fair:
+	if (to) {
+		hrtimer_cancel(&to->timer);
+		destroy_hrtimer_on_stack(&to->timer);
+	}
+	return ret != -EINTR ? ret : -ERESTARTNOINTR;
+
+uaddr_faulted_fair:
+	queue_unlock(hb);
+
+	ret = fault_in_user_writeable(uaddr);
+	if (ret)
+		goto out_fair;
+
+	if (!(flags & FLAGS_SHARED))
+		goto retry_private_fair;
+
+	goto retry_fair;
+}
 
 /*
  * Userspace tried a 0 -> TID atomic transition of the futex value
@@ -3075,6 +3227,12 @@
 	return ret;
 }
 
+static int futex_unlock_fair_pi(u32 __user *uaddr, unsigned int flags)
+{
+	/* For now, we don't need nothing different */
+	return futex_unlock_pi(uaddr,flags);
+}
+
 /**
  * handle_early_requeue_pi_wakeup() - Detect early wakeup on the initial futex
  * @hb:		the hash_bucket futex_q was original enqueued on
@@ -3310,6 +3468,15 @@
 	return ret;
 }
 
+static int futex_wait_requeue_fair_pi(u32 __user *uaddr, unsigned int flags,
+				 u32 val, ktime_t *abs_time, u32 bitset,
+				 u32 __user *uaddr2)
+{
+	/* For now, we don't need nothing different */
+	return futex_wait_requeue_pi(uaddr, flags, val, abs_time, bitset, uaddr2);
+}
+
+
 /*
  * Support for robust futexes: the kernel cleans up held futexes at
  * thread exit time.
@@ -3715,6 +3882,19 @@
 		    cmd != FUTEX_WAIT_REQUEUE_PI)
 			return -ENOSYS;
 	}
+	
+	/* Flag the thread */
+	switch(cmd){
+	case FUTEX_LOCK_FAIR_PI:
+	case FUTEX_UNLOCK_FAIR_PI:
+	case FUTEX_TRYLOCK_FAIR_PI:
+	case FUTEX_WAIT_REQUEUE_FAIR_PI:
+	case FUTEX_CMP_REQUEUE_FAIR_PI:
+		current->is_cb2lock = 1;
+	break;
+	default:
+		current->is_cb2lock = 0;
+	}
 
 	switch (cmd) {
 	case FUTEX_LOCK_PI:
@@ -3722,8 +3902,16 @@
 	case FUTEX_TRYLOCK_PI:
 	case FUTEX_WAIT_REQUEUE_PI:
 	case FUTEX_CMP_REQUEUE_PI:
+	case FUTEX_LOCK_FAIR_PI:
+	case FUTEX_UNLOCK_FAIR_PI:
+	case FUTEX_TRYLOCK_FAIR_PI:
+	case FUTEX_WAIT_REQUEUE_FAIR_PI:
+	case FUTEX_CMP_REQUEUE_FAIR_PI:
+
 		if (!futex_cmpxchg_enabled)
 			return -ENOSYS;
+		else
+			printk("[!!] We need compilation with CONFIG_HAVE_FUTEX_CMPXCHG\n");
 	}
 
 	switch (cmd) {
@@ -3755,6 +3943,19 @@
 					     uaddr2);
 	case FUTEX_CMP_REQUEUE_PI:
 		return futex_requeue(uaddr, flags, uaddr2, val, val2, &val3, 1);
+        /* New cases with next associated functions */
+	case FUTEX_LOCK_FAIR_PI:
+		return futex_lock_fair_pi(uaddr, flags, timeout, 0);
+	case FUTEX_UNLOCK_FAIR_PI:
+		return futex_unlock_fair_pi(uaddr, flags);
+	case FUTEX_TRYLOCK_FAIR_PI:
+		return futex_lock_fair_pi(uaddr, flags, NULL, 1);
+	case FUTEX_WAIT_REQUEUE_FAIR_PI:
+		val3 = FUTEX_BITSET_MATCH_ANY;
+		return futex_wait_requeue_fair_pi(uaddr, flags, val, timeout, val3,
+					     uaddr2);
+	case FUTEX_CMP_REQUEUE_FAIR_PI:
+		return futex_requeue(uaddr, flags, uaddr2, val, val2, &val3, 1);
 	}
 	return -ENOSYS;
 }
@@ -3769,7 +3970,8 @@
 	u32 val2 = 0;
 	int cmd = op & FUTEX_CMD_MASK;
 
-	if (utime && (cmd == FUTEX_WAIT || cmd == FUTEX_LOCK_PI ||
+	if (utime && (cmd == FUTEX_WAIT || cmd == FUTEX_LOCK_PI || 
+		      cmd == FUTEX_LOCK_FAIR_PI || cmd == FUTEX_WAIT_REQUEUE_FAIR_PI ||
 		      cmd == FUTEX_WAIT_BITSET ||
 		      cmd == FUTEX_WAIT_REQUEUE_PI)) {
 		if (unlikely(should_fail_futex(!(op & FUTEX_PRIVATE_FLAG))))
@@ -3966,6 +4168,7 @@
 	int cmd = op & FUTEX_CMD_MASK;
 
 	if (utime && (cmd == FUTEX_WAIT || cmd == FUTEX_LOCK_PI ||
+		      cmd == FUTEX_LOCK_FAIR_PI || cmd == FUTEX_WAIT_REQUEUE_FAIR_PI ||
 		      cmd == FUTEX_WAIT_BITSET ||
 		      cmd == FUTEX_WAIT_REQUEUE_PI)) {
 		if (get_old_timespec32(&ts, utime))
